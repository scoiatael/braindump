#+HUGO_BASE_DIR: ../
#+HUGO_SECTION: ./

* Rants                                                           :@rants:
   :PROPERTIES:
   :EXPORT_HUGO_SECTION: rants
   :END:
** DONE Software architecture                                  :architecture:
   CLOSED: [2020-01-07 Tue 14:46]
   :PROPERTIES:
   :EXPORT_FILE_NAME: software-architecture
   :END:
   Recently I began to wonder why is building software /that/ interesting?
   I quite enjoy computer and tabletop games, and somehow simply building software seems to be at least as challenging and in turn rewarding.
*** The obvious answer: joy of creation
    Though I haven't done any research in that area, I'm quite sure that in general people like creating - and by that expressing themselves, and losing themselves in the process.
    It seems a bit far-fetched to compare painting to writing code. But there is certainly a strong component of that in joy of development.
    The problem is, it doesn't describe the challenge.
*** Obvious parallel: _real_ architecture
    Let's compare software to a better known real-world profession. One that's even in the name of the challenge: architecture.
    (Please excuse my simplified view on building houses, I'm quite sure there's more to it and alternative versions.)

    There are 3 major phases: project, construction and finishing.
    Major decisions are done in the first phase.
    There is a process to ensure project is sound. There is a design language that makes plan as unambiguous as possible.

    And that's how it was done at the beginning with software: design, write, installation.
    But it turned out to be create broken products: either not fitting the client needs, getting too expensive to create or unmaintainable.

    Turns out there is a real risk of missing the goal when going this way with software.
    Hence all the Lean / Agile methodologies, Dev/Ops philosophies and a lot of good practices.
    A lot has been written on this point, so let's go in different direction: how it affects decisions being made during development process?

    In my experience, there are at least two viewpoints one has to keep in mind when programming:
    1. The system and its future
       How will what I'm writing evolve? What are the options I'm keeping open to tackle future challenges?
    2. Current set of abstractions
       What this part needs to accomplish? How do I ensure it does what it should? Can I prevent it breaking in the future?

    This seems vaguely similar: one has to win current battle while still winning the whole war.

*** Development: Total War
    These concepts already have their names: strategy and tactics.
    And so it seems the best parallel for programming might be battle games.
    Weird conclusion, but one that certainly explains the satisfaction coming from it.
    The fact that the challenge you solved wasn't described in terms of math task or campaign objective doesn't mean it wasn't as hard.

    And most likely the cognitive path you had to go through was quite similar - maybe you simply didn't realize it.

** DONE State of Python tooling                                      :python:
   CLOSED: [2020-01-19 Sun 21:39]
   :PROPERTIES:
   :EXPORT_FILE_NAME: state-of-python-tooling
   :END:
   Recently I joined a team working mostly in Python. As usual, one of the first steps is getting development environment for the projects up and running.
   The first part was quick and easy: download a couple of config files & secrets, =docker-compose up= and we are up and running.

   Then came the hard part: getting local Python environment running for tests and code-completion.
**** Preface
     I'm a big fan of [[https://github.com/direnv/direnv][direnv]] - having single =.envrc= file with all the environment variables and tool setup, shared by both terminal and editor is awesome.
     You can even create =envrc.template= and simple instructions for fellow developers on how to obtain missing values. This allows quite painless onboarding and migration between tool versions.
     Direnv also allows defining layouts for various programming languages - allowing easy setup of things like specific [[https://github.com/direnv/direnv/wiki/Node][Node]] or [[https://github.com/direnv/direnv/wiki/Ruby][Ruby]] versions.

     This works quite well with ability to define different lists of dependencies for production & development/testing - via [[https://bundler.io/v1.12/groups.html][Bundler groups]] or [[https://docs.npmjs.com/specifying-dependencies-and-devdependencies-in-a-package-json-file][npm's devDependencies]].
     As a new developer fill out =.envrc=, run =bundle install= and you are good to go.
**** So what's wrong with Python?
     Well, I remember learning about =virtualenv= at one point in 2014 and being in awe with what it brought to table: real isolation of dependencies between projects, (almost) fully automated.
     All you had to do is =source venv/bin/activate && pip install -r requirements.txt= and start coding.

     Fast forward to 2020 and somehow the same flow doesn't feel so good anymore. Why?
     - What is your Python version? What should it be? Which one is used on production? Which one will users of your library use?
     - Are you using private repository for Python packages? How are you authenticating?
     - What dependencies are needed for production setup? Which ones only for testing? And moreover, how do you update them?
**** Possible solutions
     Over the years, couple of solutions started to grow. When setting up the project I tried the following:
***** [[https://docs.python.org/3/library/venv.html][venv/virtualenv]]
      Virtualenv approach became popular enough for it to become part of stdlib in 3.3. Finally times of =pip install --user virtualenv && virtualenv venv && source venv/bin/activate && pip install -r requirements.txt= are over.

      But it didn't evolve: it isolates dependencies for given project, but doesn't try to solve any other issues. While this is a good philosophy for a library, this means we need some extra layer to take care of Python versions, dependencies, etc.
***** [[https://github.com/pyenv/pyenv][pyenv]]
      Pyenv aims to organize maintenance of several Python versions on one machine. It's based on [[https://github.com/rbenv/rbenv][a Ruby counterpart]] and therefore quite battle-tested.

      Similar to =venv=, it solves just one thing and does it well. The downside is, you again have to coordinate tools on your own.
      There are a couple of ways to achieve [[https://github.com/direnv/direnv/wiki/Python#pyenv][the direnv integration]], each with its own set of problems.
      For tools like [[https://tox.readthedocs.io/en/latest/][tox]] to work, =pyenv= supports having multiple python versions enabled at the same time.
      Now how should =virtualenv= behave? Do you want a separate env for each Python? Or just one, and let =tox= manage the rest?

      There's also one more thing to consider: how do you manage development tools for each version? Do you want =black= or =flake8= installed for each version?

      In the end I gave up on setting up =tox= in the project. I'll be running tests under just one Python and let CI test on different ones.
***** [[https://github.com/pypa/pipenv][pipenv]]
      To answer some of the issues, a new project was created. One that was supposed to implement for Python what =bundler= does for Ruby.

      Sadly, it looks weird: last release happened [[https://github.com/pypa/pipenv/releases/tag/v2018.11.26][over a year ago]], Google search for docs point over to [[https://pipenv-fork.readthedocs.io/en/latest/][a fork(?)]] instead of [[https://pipenv.kennethreitz.org/en/latest/][the official ones]], there are [[https://github.com/pypa/pipenv/issues/4058][weird rumors]] in the community.
      Now, this wouldn't be _that_ bad, if the project was mature and feature-complete - meaning I could trust it and start porting over project to it.

      Sadly, that wasn't the case for me - most likely due to me not understanding =pip= enough - but that means there will be more issues down the road.
      The specific problem I failed to overcome was using private repository for some packages when installing current package.
      It'd either try to pull all packages from it (as if pip =--index-url= flag was set), or fail to use it at all.
      That'd mean having to migrate all packages we were using to Pip at once, instead of doing it incrementally. A deal breaker for me.
***** [[https://python-poetry.org/][poetry]]
      Quite ironically, I noticed this project being advertised on one of =pipenv= Github issues.
      It's promise is to be

      #+BEGIN_QUOTE
 a single tool to manage my Python projects from start to finish.
      #+END_QUOTE

      It also pokes at =pip='s issues with dependency resolution.

      The only problem is that it uses its own Toml configuration file - meaning, again, having to port over all of our packages to this one tool.
      Maybe at some point this effort will be worth it; certainly not as a part of setting it up for a single developer.
***** [[https://asdf-vm.com/#/][asdf]]
      In the end, I was committed to using =pyenv= + =pyenv-virtualenv= plugin with one of the more magical setups from =direnv=.
      I remembered one more tool that came handy when working with Elixir: =asdf=.
      It's a generalized version manager, supporting multiple languages.
      It has both [[https://github.com/asdf-community/asdf-direnv][a direnv plugin]] and [[https://github.com/danhper/asdf-python][python one]], meaning most of the heavy lifting is already done.

      In the end, my =.envrc= looks as following:

      #+BEGIN_SRC shell
use asdf python 3.8.1
layout python
      #+END_SRC

      and achieves /almost/ what it was supposed to do; only victim was =tox= and testing for multiple Python versions.
